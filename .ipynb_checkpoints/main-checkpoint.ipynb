{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfce94e1-cd74-4752-81e4-0ef9b8da0d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, e: 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m             agent\u001b[38;5;241m.\u001b[39mmemorize(Current_State, action, Reward, Next_State)\n\u001b[0;32m    164\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size:\n\u001b[1;32m--> 165\u001b[0m                 loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m##### Output: Moving average\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "File \u001b[1;32mE:\\IRS using rINBOW\\DQN.py:77\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, action, reward, next_state \u001b[38;5;129;01min\u001b[39;00m minibatch:\n\u001b[0;32m     76\u001b[0m     ActionIndex \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(next_state, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m### Selection using DQN\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     target \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][ActionIndex]   \u001b[38;5;66;03m# Evaluation using target network\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     target_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(state, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m## DQN\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     target_f[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m target\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2651\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   2650\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2651\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menumerate_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Single epoch.\u001b[39;49;00m\n\u001b[0;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatch_stop_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:500\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    499\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:706\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    702\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 706\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:745\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    742\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    743\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    744\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 745\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3421\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3420\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3421\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3422\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3424\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from MuMIMOClass import *\n",
    "from Rainbow import *\n",
    "from MAB import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "## Simulation Parameters\n",
    "    EPISODES = 2000\n",
    "    NumAntBS = 2\n",
    "    NumEleIRS = 32\n",
    "    NumUser = 2\n",
    "    sigma2_BS = .1  # Noise level at BS side\n",
    "    sigma2_UE = .5  # Noise level at UE side\n",
    "    Pos_BS = np.array([0, 0, 10])  # Position of BS\n",
    "    Pos_IRS = np.array([-2, 5, 5])  # Position of IRS\n",
    "    MuMIMO_env = envMuMIMO(NumAntBS, NumEleIRS, NumUser) # Environment\n",
    "    batch_size = 8\n",
    "    state_size = [NumAntBS*NumUser*2, NumEleIRS * 2]\n",
    "    QuantLevel = 8  # Quantization level of Phase shift\n",
    "\n",
    "## Action Set\n",
    "    ShiftCodebook = [np.exp(1j * pi * 2 * np.arange(0, NumEleIRS, 1) / NumEleIRS),\n",
    "                     np.exp(-1j * pi * 2 * np.arange(0, NumEleIRS, 1) / NumEleIRS),\n",
    "                     np.exp(3j * pi * 2 * np.arange(0, NumEleIRS, 1) / NumEleIRS),\n",
    "                     np.exp(-3j * pi * 2 * np.arange(0, NumEleIRS, 1) / NumEleIRS),\n",
    "                     np.exp(0j * pi * 2 * np.arange(0, NumEleIRS, 1) / NumEleIRS)]\n",
    "    ShiftCodebook = np.array(ShiftCodebook)\n",
    "    action_size = np.size(ShiftCodebook, 0)\n",
    "\n",
    "## Channel Dynamics\n",
    "    block_duration = 1  ### When block_duration>1, ESC will be applied\n",
    "    BlockPerEpi = 20\n",
    "    TimeTotal = BlockPerEpi * block_duration\n",
    "\n",
    "## DDQN\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "## MAB\n",
    "    MABagent = MAB(NumEleIRS)\n",
    "\n",
    "## Initialization\n",
    "    RateExCount = np.zeros(action_size)\n",
    "    Rate_DQN_seq_episode = np.zeros(EPISODES)\n",
    "    Rate_Random_seq_episode = np.zeros(EPISODES)\n",
    "    Rate_MAB_seq_episode= np.zeros(EPISODES)\n",
    "\n",
    "    RefVector = np.exp(1j * pi * np.zeros((1, NumEleIRS)))\n",
    "    RefVector_bench_random = RefVector\n",
    "    Pilot = MuMIMO_env.DFT_matrix(NumUser)  ## Plot pattern\n",
    "    ArrayShape_BS = [NumAntBS, 1, 1]  ## array shape\n",
    "    ArrayShape_IRS = [1, NumEleIRS, 1]  ##\n",
    "    ArrayShape_UE = [1, 1, 1]  ## UE is with 1 antenna\n",
    "\n",
    "    Rate_Random_seq_block = np.zeros(BlockPerEpi)\n",
    "    Rate_DQN_seq_block = np.zeros(BlockPerEpi)\n",
    "    Rate_MAB_seq_block = np.zeros(BlockPerEpi)\n",
    "\n",
    "###########################################\n",
    "    for epi in range(EPISODES):\n",
    "        Pos_UE = np.array([[np.random.rand() * 10, np.random.rand() * 10, 1.5], [np.random.rand() * 10, np.random.rand() * 10, 1.5]], dtype=float)\n",
    "        H_U2B_LoS, H_R2B_LoS, H_U2R_LoS = MuMIMO_env.H_GenFunLoS(Pos_BS, Pos_IRS, Pos_UE, ArrayShape_BS, ArrayShape_IRS, ArrayShape_UE)  ## LoS component\n",
    "        SumRate_seq = np.zeros(block_duration) ### Check the performance of ESC\n",
    "\n",
    "        for block in range(BlockPerEpi):\n",
    "            H_U2B_NLoS, H_R2B_NLoS, H_U2R_NLoS = MuMIMO_env.H_GenFunNLoS(NumAntBS, NumEleIRS, NumUser)\n",
    "            K = 10 ## K-factor\n",
    "            H_U2B = sqrt(1 / (K + 1)) * H_U2B_NLoS + sqrt(K / (K + 1)) * H_U2B_LoS\n",
    "            H_R2B = sqrt(1 / (K + 1)) * H_R2B_NLoS + sqrt(K / (K + 1)) * H_R2B_LoS\n",
    "            H_U2R = sqrt(1 / (K + 1)) * H_U2R_NLoS + sqrt(K / (K + 1)) * H_U2R_LoS\n",
    "            H_synt = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector[0])  ### The aggregated wireless channel\n",
    "\n",
    "####################################################################################\n",
    "            DFTcodebook = sqrt(NumEleIRS) * MuMIMO_env.DFT_matrix(NumEleIRS)\n",
    "\n",
    "### Benchmark: Random Reflection\n",
    "            random_index = random.randrange(len(DFTcodebook))\n",
    "            RefVector_bench_random = DFTcodebook[random_index, :]\n",
    "            H_synt_bench = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector_bench_random)\n",
    "            Rate_bench, _, _ = MuMIMO_env.GetRewards(Pilot, H_synt_bench, sigma2_BS, sigma2_UE)\n",
    "            random_rate = sum(Rate_bench)\n",
    "            Rate_Random_seq_block[block] = random_rate\n",
    "\n",
    "### Benchmark: Multi-arm bandit\n",
    "            act_index = MABagent.act_sel()\n",
    "            RefVector_bench_MAB = DFTcodebook[act_index, :]\n",
    "            H_synt_bench = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector_bench_MAB)\n",
    "            Rate_bench, _, _ = MuMIMO_env.GetRewards(Pilot, H_synt_bench, sigma2_BS, sigma2_UE)\n",
    "            MAB_rate = sum(Rate_bench)\n",
    "            MABagent.Q_update(act_index, MAB_rate)\n",
    "            Rate_MAB_seq_block[block] = MAB_rate\n",
    "### Benchmark Ends\n",
    "\n",
    "\n",
    "############################# Current State\n",
    "            if block==0:\n",
    "                Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "                H_est_vector = np.reshape(H_est, (1, NumAntBS * NumUser))\n",
    "                Current_State = [np.concatenate((H_est_vector.real, H_est_vector.imag), axis=1), np.concatenate((RefVector.real, RefVector.imag), axis=1)]\n",
    "            else:\n",
    "                Current_State = Next_State\n",
    "\n",
    "############################# Action\n",
    "            Flag = 1 ## Flag for ESC\n",
    "            for i_time in range(block_duration):\n",
    "                Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "                H_est_vector = np.reshape(H_est, (1, NumAntBS * NumUser))\n",
    "                if i_time == 0: ## Coarse phase shift\n",
    "                    if epi == 0:\n",
    "                        action = random.randrange(len(ShiftCodebook))\n",
    "                        act_type = 'random'\n",
    "                    else:\n",
    "                        action, act_type = agent.act(Current_State)\n",
    "                    RefVector = RefVector * ShiftCodebook[action, :] ## Action: Absolute phase shift\n",
    "                    H_synt = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector[0])\n",
    "                    Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "\n",
    "                ### Estimate the rate, exclusively used in ESC\n",
    "                    Rate_est, _, _ = MuMIMO_env.GetRewards(Pilot, H_est, sigma2_BS, sigma2_UE)\n",
    "                    SumRate_seq[i_time] = sum(Rate_est) ##\n",
    "\n",
    "                else:  ## Fine Phase Shift  -- Dither\n",
    "                    if Flag == 1:  ## When Flag == 1, generate a dither\n",
    "                        ### Dither based search\n",
    "                        Dither = np.exp(1j * 2 * pi * 1 / (2 ** QuantLevel) * (np.random.randint(8, size=(1, NumEleIRS)) - 4)) ## a small-scale dither\n",
    "                        RefVector = RefVector * Dither[0]\n",
    "                        H_synt = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector[0])\n",
    "                        Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "                        ######################## Estimate the rate\n",
    "                        Rate_est, _, _ = MuMIMO_env.GetRewards(Pilot, H_est, sigma2_BS, sigma2_UE)\n",
    "                        SumRate_seq[i_time] = sum(Rate_est)  ## Estimated Performance\n",
    "                        #############\n",
    "                        if SumRate_seq[i_time] > SumRate_seq[i_time - 1]:\n",
    "                            Flag = 1\n",
    "                        else:\n",
    "                            Flag = -1\n",
    "\n",
    "                    else:  ## When Flag == -1, generate the phase shift vector that is opposite to the dither, i.e., np.conj(Dither[0]) * np.conj(Dither[0])\n",
    "                        RefVector = RefVector * np.conj(Dither[0]) * np.conj(Dither[0])\n",
    "                        H_synt = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector[0])\n",
    "                        Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "                        ######################## Estimate the rate\n",
    "                        Rate_est, _, _ = MuMIMO_env.GetRewards(Pilot, H_est, sigma2_BS, sigma2_UE)\n",
    "                        SumRate_seq[i_time] = sum(Rate_est)\n",
    "                        Flag = 1\n",
    "\n",
    "            H_synt = MuMIMO_env.H_syntFun(H_U2B, H_R2B, H_U2R, RefVector[0])\n",
    "            Rate, y_rx, H_est = MuMIMO_env.GetRewards(Pilot, H_synt, sigma2_BS, sigma2_UE)\n",
    "            Rate_DQN_seq_block[block] = sum(Rate)   ## Performance feedback\n",
    "\n",
    "############################# Reward\n",
    "            if Rate_DQN_seq_block[block] > 10:  ## Threshold -- 10\n",
    "                Reward = Rate_DQN_seq_block[block]\n",
    "            else:\n",
    "                Reward = Rate_DQN_seq_block[block] - 100 ## Penalty\n",
    "\n",
    "############################# Next State\n",
    "            H_est_vector = np.reshape(H_est, (1, NumAntBS * NumUser))\n",
    "            Next_State = [np.concatenate((H_est_vector.real, H_est_vector.imag), axis=1), np.concatenate((RefVector.real, RefVector.imag), axis=1)]\n",
    "\n",
    "############################# Memorize\n",
    "            agent.memorize(Current_State, action, Reward, Next_State)\n",
    "            if len(agent.memory) > batch_size:\n",
    "                loss = agent.replay(batch_size)\n",
    "\n",
    "##### Output: Moving average\n",
    "        N = 64\n",
    "        if epi>=N:\n",
    "            print(\n",
    "                \"episode: {}, e: {:.2}, MovingAveRLearning:{:.4f}, MovingAveRandom:{:.4f}, MovingAveMAB:{:.4f}\".format(\n",
    "                    epi, agent.epsilon, np.mean(Rate_DQN_seq_episode[epi-N:epi]), np.mean(Rate_Random_seq_episode[epi-N:epi]), np.mean(Rate_MAB_seq_episode[epi-N:epi]))\n",
    "            )\n",
    "        else:\n",
    "            print(\"episode: {}, e: {:.2}\".format(epi, agent.epsilon) )\n",
    "\n",
    "        if epi % 20 == 0: ################## Update target model\n",
    "            agent.update_target_model()\n",
    "            agent.save(\"./IRS_DQN.h5\")\n",
    "\n",
    "        Rate_DQN_seq_episode[epi] = np.mean(Rate_DQN_seq_block)\n",
    "        Rate_Random_seq_episode[epi] = np.mean(Rate_Random_seq_block)\n",
    "        Rate_MAB_seq_episode[epi] = np.mean(Rate_MAB_seq_block)\n",
    "\n",
    "\n",
    "##########################  PLOT\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    localtime = time.localtime(time.time())\n",
    "    print(localtime)\n",
    "\n",
    "    dataframe = pd.DataFrame({'Rate_DQN_seq_episode': Rate_DQN_seq_episode,\n",
    "                              'Rate_Random_seq_episode': Rate_Random_seq_episode,\n",
    "                             'Rate_MAB_seq_episode': Rate_MAB_seq_episode})\n",
    "    dataframe.to_csv( \"Rate\"  + str(localtime)  +  \".csv\", index=False, sep=',')\n",
    "\n",
    "    def get_moving_average(mylist, N):\n",
    "        cumsum, moving_aves = [0], []\n",
    "        for i, x in enumerate(mylist, 1):\n",
    "            cumsum.append(cumsum[i - 1] + x)\n",
    "            if i >= N:\n",
    "                moving_ave = (cumsum[i] - cumsum[i - N]) / N\n",
    "                moving_aves.append(moving_ave)\n",
    "        return moving_aves\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.xlabel('Time', fontsize=14)\n",
    "    plt.ylabel('Rate', fontsize=14, labelpad=-2)\n",
    "\n",
    "    SumRate_seq_ave = get_moving_average(Rate_DQN_seq_episode, N)\n",
    "    RandomRate_seq_ave = get_moving_average(Rate_Random_seq_episode, N)\n",
    "    MABRate_seq_ave = get_moving_average(Rate_MAB_seq_episode, N)\n",
    "\n",
    "    plt.figure()\n",
    "    x = np.arange(len(SumRate_seq_ave)) + N\n",
    "    plt.plot(x, SumRate_seq_ave, 'r-', linewidth=3)\n",
    "    plt.plot(x, RandomRate_seq_ave, 'g-', linewidth=3)\n",
    "    plt.plot(x, MABRate_seq_ave, 'k-', linewidth=3)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Performance $P_m$ (bps/Hz)\")\n",
    "    plt.legend(['ReLearning', 'Random','MAB'])\n",
    "    plt.savefig('destination_path.eps', format='eps')\n",
    "    plt.savefig('destination_path.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e7bad-01d5-45dc-9cc9-07a1e751a1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
